## 搜狗商业平台基础架构演化实践

文/刘建，董泽光

本文以搜狗商业平台近年来的基础架构演化为背景，介绍其中主要阶段：水平化阶段、服务化阶段和流式计算阶段中的基础架构演化、应用流程以及相关实践经验，也介绍了在业务快速迭代过程中逐步形成的基础架构，以及构建基础架构的原则、经验和思考。

### 基础架构演化概述

搜狗商业平台基于搜狗云端产品矩阵，对产品进行商业化。它涵盖了搜索、无线、网盟、品牌、客户关系管理、业务支持等系统，提供十亿量级以上在线广告管理，几十亿量级的在线报告查询。其中，基础架构平台起到基础性支撑作用，为构建系统提供了“砖和瓦”。我们的基础架构构建于 OS、硬件和网络层之上，提供高性能、高可用、高可扩展的基础架构，降低技术风险。一般说来，基础架构越好，业务迭代会更加迅速，有助于快速构建、部署、监控和分析应用，提升效率，减少成本。

一般说来，基础架构会涉及到两个团队：基础技术团队和业务团队。两个团队的职责和目标是有一些冲突的，而这会对基础架构的设计、构建、应用部署产生一定的影响。对于基础技术团队来说，需要考虑做什么事情、怎么做、做到什么程度，需要考虑到技术的前瞻性以及基础架构的规范性。对于业务团队来说，需要考虑项目进度、成本和风险。其中风险是技术升级及基础架构演化中最大的问题，特别是对于我们商业平台来说，会直接关系到收入损失。业务团队一般是风险厌恶型，而技术团队是风险偏好型。它们之间需要进行协调，从而推动整体基础架构的演化和发展。我们的基础架构也是在一步一步的实践中逐步发展起来的，分为四个阶段：

1. 初始阶段
2. 水平化阶段
3. 服务化阶段
4. 流式计算阶段

其实，同大多数小型开发团队一样，我们基础架构的初始阶段采用的策略是业务优先，技术服务于业务。业务初期采用快速构建模式，优先功能需求，对于性能考虑较少。团队相对独立，基本上是依靠研发人员的经验，选择合适/熟悉的技术，应用开源软件，协作相对简单。在交互上，一般采用数据库在团队间进行数据共享。在这个时候，没有独立的基础架构，基础架构和业务间的界限并不明显。随着业务高速发展，我们也陆续遇到了一些问题，比如性能降低、可维护性变差、协作成本变高、数据一致性等。水平化阶段主要是解决性能问题，服务化阶段主要解决可维护性及协作成本问题，流式计算阶段主要在性能和数据一致性间取得一个平衡。下面来看看我们在每个阶段所做的工作。

### 水平化阶段

随着业务的发展，广告量增长迅速，性能问题逐步出现，当存储的广告量达到大约8000万时，引起了数据库健康度低和访问超时率高两个问题。当时，我们的数据库 I/O 以及 CPU 的压力都较大，健康度也一直维持在警戒线以上。在 Web 层面，我们要求99%的请求在4秒内完成，但是广告管理有很多广告列表以及批量操作，这些操作的平均响应时间变长，导致无法满足此约束。事实上，当时我们的报告存储也面临很大的压力，当时基于数据库进行报告统计，在数据量大的情况下，有些统计 SQL 的执行时间超过1个小时并且存在恢复时间长等一系列问题。其实，我们当时面临着硬件资源（数据库）无法满足应用性能需求的问题。对于计算资源来说，无法在要求的时间给出计算结果。对于存储资源来说，其 I/O 和 TPS 无法满足应用需求。

解决此类问题的通用方案是进行水平扩展。我们将水平化分为计算水平化和存储水平化两类。

 - 计算水平化：主要涉及计算资源的扩展，例如 We b应用、后台计算任务等。
 - 存储水平化：主要涉及存储资源的扩展，例如 MySQL、MongoDB、Oracle、大文件等。

计算水平化相对简单一些。计算可分为无状态计算和有状态计算两种。无状态计算可直接通过负载均衡等机制进行水平扩展。有状态计算需要通过一种机制支持状态的有效共享，一般情况下可通过状态存储（可通过 Cookie、分布式会话、分布式缓存等机制）、状态复制等来完成状态在多个计算节点间的共享。对于有状态计算来说，需要注意避免全局的计算，一些算法（特别是机器学习算法）需要对全局状态进行不停的迭代，对这种计算进行水平化就比较复杂。此阶段我们所做的工作主要是分布式会话、分布式缓存以及单机迁移多机，保证架构可水平迁移（期间也应用了 Hadoop）。

存储水平化相对复杂一点，存储的水平扩展性一般涉及到读和写，对于读来说，可通过更多的副本来支持更多的读，这些可以通过对存储的复制来完成，不过值得注意的是复制过程中需要留心网络延时和数据的一致性问题。对于写来说，此种情况下一般只能对数据进行拆分，提供更多的写实例来完成。在存储水平化阶段我们所做的主要工作是数据库分库分表框架 Compass、MongoDB 分库分表框架和数据库全量/实时报文水平切分。下面我们以[数据库分库分表框架 Compass](https://github.com/sogou-biztech/compass)为例来介绍一下我们的架构设计及应用原则。

首先，我们内部有很多应用系统使用了数据库，不同的应用访问量不同，对数据库资源的利用率不同，导致其部署方式存在差异。根据其资源使用情况可分为主从库、分库、分表、分库分表等多种数据库部署模式，因此，作为数据库分库分表框架，必须同时支持这些部署模式。其次，为了支持线上用户的访问，框架也必须支持读写分离和负载均衡等机制。最后，为了方便各个业务系统以尽可能小的代价迁移到新的框架上面，该框架需要遵循标准的数据源接口（Java 语言中的 DataSource 接口）。

数据库分库分表框架 Compass 架构图如图1所示。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689e70f574e9.png)

图1 数据库分库分表框架 Compass 架构图

其中，分库数据源和主从数据源都支持 DataSource 接口，对上层应用屏蔽了底层数据库部署的差异。路由策略根据应用程序中的上下文信息选择具体的主从数据源，主从选择策略根据应用程序中的上下文信息选择将具体的请求分配到主库还是从库执行。数据源心跳探测模块探测数据源的可用性。连接池监控管理监控连接池的状态信息，例如活跃连接数等。分表规则内置在主从数据源中，目前支持通过 SQL 解析（利用 SqlParser）或占位符等方式进行分表。其中，路由规则、分表规则都可以自行进行扩展。

应用迁移到 Compass 框架上主要包括三个阶段：

1. 框架集成：主要对数据源配置进行平滑迁移；
2. 接口迁移：主要对使用数据源的应用程序接口逐步迁移到 Compass 框架；
3. 数据迁移：数据进行水平拆分时需要对数据进行迁移，目前主要是通过脚本进行迁移，此过程可能涉及到一定的停机时间。

下面我们来看一个例子，如图 2所示。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689e7346b139.png)

图2  应用迁移到 Compass 框架实例

假设应用系统原来使用数据库访问框架A，其上有接口 A 和接口 B 使用框架 A，如阶段1所示。在框架集成阶段（阶段2），主要目标是对 Compass 进行配置，使得其能够访问底层的数据库。在接口集成阶段（阶段3），可逐步将访问框架 A 的接口 A 和接口 B 逐步迁移到 Compass 框架上。在数据迁移阶端（阶段4），对底层的数据库进行拆分，然后复制到多个主从库中，同时调整 Compass 配置，使得其从主从库的部署调整到分库的部署（可能还分表）。至此，完成了数据库的水平化拆分。在此过程中，框架集成和接口迁移可随着业务版本的开发和测试同时进行，仅仅数据迁移可能涉及到停机切换，这样能够有效的降低风险，同时也将整体迁移任务拆分到多个业务版本中，更适应于业务快速迭代的场景。当然，也有一些场景需要注意，特别是关于聚合统计、存储过程、全表的过滤查询等，Compass 虽然提供了聚合框架，但是其在一些场景下执行效率较低，或者占用内存较大，此时就需要考虑采用其他方式。

在水平化的过程中，我们基本遵循着以下的实践经验：

1. 尽量保持接口的兼容性，Compass 框架遵循标准的 DataSource/Connection 接口，MongoDB 分库分表框架遵循 com.mongodb.* 中的接口（Mongo/DB/DBApiLayer）。接口的兼容性有助于历史资产的迁移。
2. 保持新旧框架的兼容性，从影响小的功能点开始，平滑迁移，通过“框架集成”、“接口迁移”和“数据迁移”对系统进行平滑迁移，同时有效的降低了迁移过程中的风险。
3. 保持存储（数据库）下一次水平扩展的简单性。一般情况下，存储的水平化迁移后，未来一段时间内可能需要继续进行水平化迁移，因此可以为未来的一次或多次水平化迁移留出空间，可直接将数据拆分成其所需要的份数，同时基于现有资源进行部署（例如，将2份或者更多份数据部署在一组机器上），这样后续水平化迁移时无需再次拆分数据，能够减少工作量。对于数据库来说，将已经切分且部署在同一组机器上的两份数据迁移到两组机器上，所需要做的事情仅仅是同步和主从切换，相对比较简单。

### 服务化阶段

随着业务的发展，系统的可维护性也逐步变差。在我们的业务中有一个广告核心库被多个业务同时使用，导致定位问题难、联动大、效率低。同时，公有基础模块越来越多，同一个功能存在多个模块和版本：缓存、短信、消息、数据、报告存储，复杂的包依赖导致包冲突变多，升级复杂。其次业务版本也存在可维护性问题，多版本并行研发，项目风险增加，导致回归成本变高。最后，由于业务加速，协作越来越多，业务线间的协作成本也逐步变高，在语言上，使用比较广泛的语言包括 Java、C++、Python。在跨业务线调用方式更是种类繁多，包括 RMI、Hession、ICE、HTTP/JSON，TCP+ 自定义格式、依赖相关类库（或数据库）等，经常需要对接口适配，对数据进行导入导出，效率低下。服务化是解决可维护性，提高协作效率的有效方式。它可以使得资源私有，同时基于接口进行交互，使得功能能够自治和独立演化，大大增强了可维护性，同时也降低耦合，降低了协作成本。在服务化阶段，我们完成了数据库资源（广告、用户、资金等）、短信/邮件通道 、图片服务、登录授权服务等的私有，同时提供基于接口的服务，沉淀了一些公有基础组件。

我们的服务化框架如图 3所示。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689e8af114db.png)

图3  服务化框架

服务化基础框架 Polaris 提供服务化组件和服务访问组件。其服务端可将接口暴露成 HTTP 服务，提供认证、授权、监控等能力，其客户端可使用接口调用的方式访问服务，提供失败重试、防重发、负载均衡等能力。服务化测试框架主要包括线上引流框架及服务单元测试框架，主要支持将线上流量引入线下，以便更好的支持单元测试。服务追踪框架对服务的调用链进行追踪和分析，从而提前发现瓶颈，进行服务的持续优化。服务注册提供服务注册和发现。服务管理涵盖服务申请、服务权限（访问白名单）、频度控制等的管理。其中，服务化基础框架是服务化的基础。

在服务化的基础框架选择上，我们选择了 Thrift，因为它具备接口可描述性高、高性能、跨语言、多种编码方式和社区活跃度高等优点。其缺点主要是类型侵入性过强，开发人员需要编写很多代码进行类型适配工作（包括处理面向对象语言中的空指针）。然而，我们也看到，也有一些公司在这方面做持续的努力（比如 Facebook Swift 产生的代码就比较接近于 POJO 及接口了）。Polaris 框架基于 Thrift 进行了增强，除了提供服务端和客户端之外，也对 Thrift 接口进行了封装，将其封装成 Thrift 服务，并且提供了本地和远程两种 Thrift 服务实现，使得在仅改变配置的情况下，就能够在本地服务调用和远程服务调用间进行切换，从而降低测试和迁移成本。

例如，假设有 PingTService 服务及其 Iface 接口实现 PingServiceImpl：

```
public class PingTService {
  public interface Iface {
      public String ping() throws org.apache.thrift.TException;
```

客户端调用如下，其中通过工厂维持了一个接口到其Thrift服务的映射。

```
PingTService.Iface client = factory.getClient(PingTService.Client.class);
       String result = client.ping();
```

此 Thrift 服务的本地服务调用配置如下：

```
<bean id="pingThriftService" class="com.sogou.bizdev.polaris.client.local.LocalThriftService">
       <property name="localHander" ref="pingService"></property>
</bean>
<bean id="pingService" class="com.sogou.bizdev.polaris.server.ping.impl.PingServiceImpl"/>
```

其远程服务调用（HTTP）配置如下：

```
<bean id="pingThriftService" class="com.sogou.bizdev.polaris.client.http.HttpThriftService">
    <property name="clientClass" value="com.sogou.bizdev.polaris.server.ping.PingTService.Client"></property>
    <property name="url" value="http://127.0.0.1/xapi/ping"></property>
    <property name="apiKey" value=""></property>
    <property name="apiSecret" value=""></property>
</bean>

```

可以看到，在本地到远程的切换过程中，仅需调整配置，无需调整代码。这样可以使用其本地调用模式进行接口测试，通过调整配置可以直接将其切换成 HTTP 调用。在测试和切换时相对比较方便，风险较小。

图4展示了广告平台中实际的切换过程，在本地调用阶段，我们首先对访问报告库和广告库的模块进行了梳理，形成了报告统计和广告管理模块，其他模块（包括报告统计控制层、广告列表、广告优化）都依赖于报告统计和广告管理模块提供的接口访问底层的数据。其次，逐步将报告统计和广告管理模块中的接口调整为 Polaris 框架中的 Thrift 接口。在远程切换阶段，我们可逐步将报告统计和广告管理模块中的接口通过 Polaris 框架发布成 HTTP 接口，同时调整其他模块（包括报告统计控制层、广告列表、广告优化）中对此接口的访问为远程服务调用（HTTP）配置即可。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689ea2505d57.png)

图4  服务化过程中本地调用到远程调用的切换

在服务化阶段，我们形成了服务层，对底层的数据库资源等进行了私有化，它大大提高了系统的可维护性，对于高并发、大数据量问题可以按平台分而治之，例如：数据库扩容、主从同步读写分离、服务器水平扩展等。同时也基于标准的接口交互文件进行交互，有效降低了沟通成本。在此阶段，我们形成了统一登录、用户管理、权限管理、日志、唯一号、图片服务等基础服务。

在服务化的过程中，我们也遵循着一些实践经验：

1. 基础服务框架一定要跨语言，为未来留下扩展性。
2. 尽可能的通过接口描述语言（IDL）进行交互，服务提供者无法预知消费者使用的框架，提供客户端组件会带来一定程度的维护成本（包括语言、平台、框架、依赖），特别是在接口升级的时候。一般情况下，接口描述语言的兼容性会更好一些。
3. 通过“本地调用”和“远程调用”两阶段进行平滑迁移，从低优先级服务开始，能有效降低风险，同时也可以和业务版本同步进行。
4. 服务化必须关注服务全流程管理，包括服务注册、服务调用、服务追踪、监控与度量、服务下线。

### 流式计算阶段

在联盟展示广告上，我们有一个非常优质的资源：搜狐矩阵。它是搜狐一系列优质媒体资源的集合。广告是否能够在搜狐矩阵上投放有两点要求：1. 客户必须在网盟投放平台上选择该广告是否投放搜狐矩阵；2. 后台任务定时推送的具备相关性的广告中包含此广告，且此广告被客服在广告审核平台中审核通过，如图5所示。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689ea729bc60.png)

图5  搜狐矩阵广告审核

为了提高审核效率，客服仅审核选择了投放搜狐矩阵的广告，由于客户是否选择投放搜狐矩阵是一个实时状态，因此广告审核平台需要向网盟投放平台实时查询广告是否投放了搜狐矩阵，该查询效率较低，性能不理想。若不进行查询，则客服可能审核了大量的没有选择投放搜狐矩阵的广告，体验不友好。其实我们面对很多这样的场景：比如各种广告优化。它都需要将两个不同业务系统中的数据做关联查询，并且依赖于一些实时状态时，就可能产生此问题。其中的关键问题是实时状态没有从一个系统同步到另外一个系统，我们是通过流式计算解决此问题，我们希望把实时的状态（比如客户是否选择投放搜狐矩阵）流式的推送到其使用者端，同时兼顾性能和用户体验。

流式计算的目标是让数据能够“流动”起来，下游的应用可以根据其需求接收和处理其感兴趣的数据。流式计算框架分成5个层次，如图6所示。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689eab6056e1.png)

图6  流式计算框架

数据层是框架能够处理的数据，我们要求数据有一定的持久化能力，便于故障恢复，目前仅支持文件和数据库。接入层通过 Kafka Producer 对文件进行流式接入，通过 Pump（基于 Trigger）和 Binlog Tunnel（基于 MySQL Binlog）对数据库中的数据进行流式接入。服务层主要使用基于 Kafka 的实时日志发布订阅框架。消费层主要是通过 Kafka Consumer 和 Strom 进行消费。应用层是基于流式计算框架的下游应用，包括安全、审计、监控、统计分析等。其中，基于 Kafka 的实时日志发布订阅框架是此流式计算框架的核心。

Kafka 是 Linkedin 提供的高性能分布式日志发布框架，我们针对商业平台的特征对其进行了优化，主要在如下几个方面：

1. 在 Kafka Producer 端，我们支持断点续传，同时支持自定义扩展，有效的保证日志中的数据都能够收集到 Kafka 集群中，不会漏掉数据。
2. 在 Kafka 集群上，我们添加了更细粒度的权限控制，能够控制到应用和主题，有效的保证了数据的安全性。
3. 我们也提供了管理控制台，能够对主题、顺序号等进行管理，对节点进行监控，有效的提升了运维的效率。

在流式计算的应用上，我们也是通过双路来有效的降低风险。以日志库的流式计算的改造为例，如图7所示，商业广告平台中，所有的广告 API 都会记录操作日志，该操作日志将写入日志库，并通过日志查询 API 提供日志查询。在双路时，广告 API 会双写日志，除了写入数据库之外，还会写入一份本地日志文件。我们通过部署一个 Kafka Producer 将本地日志文件收集到 Kafka 集群中。同时，新部署了日志写入消费者会消费此日志，将此日志写入新的日志库（结构同原有日志库一致）。这样可以对新旧日志库进行定时比对，并根据比对的结果进行调整。在经过一段时间的比对，确认完全一致之后，则将日志查询 API 由日志库切换到新的日志库中，同时将广告 API 的双写调整为仅写本地日志文件即可。如此，完成了流式计算的双路切换。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689eaf9b22c5.png)

图7  流式计算应用流程

流式计算中，也有一些实践经验：

1. 必须关注顺序性对应用的影响，分布式环境中接入端和消费端都没有办法保证全局顺序，若应用对顺序性有要求，需要自行考虑额外技术手段，比如在日志中添加唯一序列号并且在消费者端进行局部排序。
2. 关注数据重复和数据丢失：我们的应用特性要求数据不能丢失，因此在生产者会进行重试，在出现网络故障或者灾难场景时会导致消息重复，消费端需要处理数据重复问题。另外，Kafka 集群在极端情况下会出现消息丢失，需要多加注意。
3. 通过双路比对降低风险。

### 总结

我们走过了水平化、服务化和流式计算阶段，在这几个阶段中，我们的基础架构也在不停地演化。在每个阶段中，我们都应用了一些开源组件，并针对自身业务的特点，形成了自己的一些基础框架来解决未来一段时间的问题。我们设计和实现的一些组件应该可以满足未来较长一段时间的需求。同时，我们也会通过监控等手段提前发现线上的风险及问题，提前规划。 

目前，我们的基础架构主要需要解决分布式、高并发、大数据量、强一致性等带来的各种技术难题及挑战，构建和持续优化基础服务，保证高可靠、高性能、高可扩展性、低成本的快速支撑各项新业务。基础架构图如图8所示，分为三个层次。

![](http://ipad-cms.csdn.net/cms/attachment/201601/5689eb764de87.png)

图8  基础架构图

1. 基础平台：主要是我们使用的基础框架，包括SOA框架、数据库分库分表框架、数据存储、数据缓存、离线/在线数据处理、分布式一致性协调等方面的框架等。部分框架是基于开源技术构建，所利用的开源软件主要包括：Spring、Redis、Mysql、MongoDB、Hadoop、Kafka、Storm、ZooKeeper 等。
2. 基础服务：主要提供业务无关的通用基础服务，包括唯一序列号服务、数据传输/同步服务、认证、授权、配置、分布式任务调度、消息、图片、短信和邮件等。
3. 核心服务：主要是同业务相关的服务，比如计费服务、审核服务等。

从基础架构的构建来说，我们也从实践中总结了一些经验。

1. 保持接口兼容性：业务和技术团队都希望技术架构能够尽快统一，但是涉及到风险、项目进度、成本等的影响，所以基础架构演化是一个长期行为。因此，接口兼容性就非常重要，它为一段时间内同类框架共存提供了基础（例如，Sogou Compass 提供了标准的 DataSource 接口），能够平滑进行迁移和切换，能够有效抵御风险、项目进度、成本等带来的影响。
2. 控制风险：尽量避免一刀切，可通过双路和灰度方案逐步进行；同时，提供良好的迁移流程，同时通过监控等运维手段，有效降低风险。事实上，我们在水平化阶段、服务化阶段和流式计算阶段，都提供了比较完善的应用流程。
3. 易用性：简化接口，提高基础组件的易用性，从而提升开发效率，降低出错成本。例如，服务化框架提供了类RPC接口，使用方式同本地方法调用一样，因此研发人员可以很快上手，且不易出错，能显著降低错误处理成本。
4. 关注开源：关注开源社区及主流开源组件，基于业务需求评估、选择和优化开源组件。对于大规模使用的基础性开源软件，一定要熟悉其设计、运维和监控等，从而保证极端场景下能够有技术人员进行处理。

当然，技术的发展永无止境，基础架构的演化也不会停止，我们仍会持续优化基础架构，近一段时间我们关注的点主要是弹性计算和动态扩容、研发测试运维一体化和自动化、提升服务自管理和自监控能力等，希望能够有效的降低成本，降低风险，保证了商业广告平台的稳定性、可靠性和性能，保证快速业务迭代下的敏捷性。