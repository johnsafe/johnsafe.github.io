## 美团酒店 Node 全栈开发实践

文/郭凯

>前后端分离带来了全新的前后端协作方式，让专业的人做专业的事。本文介绍了美团酒店事业部的前后端分离推进过程，及应用Node进行全栈开发的心得，以此为引子，重点分享了酒店事业部的前后端分离架构。

### 前后端分离的背景

“前后端分离”显然已不是什么新鲜的话题，Web 技术专家 Nicholas C · Zakas 在2013年10月份就曾发表过一篇博客《Node.js and the new web front-end》讨论 Node 背景下新时代的前端。毫无疑问，Node的出现给 JavaScript 语言带来了新的生机，也使得前端开发者有了更多的可能性。

前后端分离表面上看似乎是一场“圈地运动”，但实质上前后端分离是为了解决以往开发模式的一些诟病和痛点，同时也是迎合大的行业趋势的明智之举。我所在的美团酒店事业部去年7月份成立，新的业务、新的开发团队，这一切使得我们的前后端分离推进得很彻底。截至目前，前端承载的所有业务和线上服务都是基于 Node.js，生产环境已经有近60台服务器。如此带来的全新前后端协作方式能够让专业的人做专业的事，无论前端后端都能较之前更专注在自己擅长的方面。

### 开发模式、技术栈

传统的开发模式只需要专注在多终端的呈现上（浏览器、WebView）。而现在，浏览器只是前端的其中一环，延伸出来的还有 Node 端的架构、服务的运维能力等。图1为我们目前的服务架构：Nginx 位于 Node 服务之前，用做负载均衡、服务调度、Gzip 压缩等。之后便是 Node 服务，我们通过 PM2.5 进行 Node 服务的 Cluster 部署和负载均衡（充分利用多核优势），同时作为轻量的中间层，负责路由、Controllers、Views 以及视图的渲染，数据的获取通过 RESTful 的 API 接口使用 JSON 格式交互。而后端则只需负责业务逻辑、数据存储、Models，并为前端提供 JSON 数据即可。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/5728650d26322.jpg" alt="图1  美团酒店服务架构" title="图1  美团酒店服务架构" />

图1  美团酒店服务架构

这样改变之后，Node 端可以进行首屏渲染等页面加载方面的优化，而后续的交互、渲染都交由浏览器端的 JavaScript 代码来完成。Node 端的模板和浏览器端的模板大部分情况下都是相同的，所以需要考虑模板重用的问题。我们用 Juicer 替换了 Express 框架默认的模板引擎，Juicer 是一个高效、轻量的前端 (JavaScript) 模板引擎，效率和易用是它追求的目标。除此之外，它还可以运行在 Node.js 环境中。通过 Juicer，可以解决 Node 端和浏览器端的模板、Helper 复用问题。而且基于前后端分离的工程架构下，前端的代码仓库和后端隔离，前端独立负责前端静态资源文件、模板文件、Controller 的维护和发布。

按照这样重新定义前后端分工之后，前端可以做的事情较以往更多了。比如微信 SDK 的接入，因为微信 JS SDK 的使用需要在服务端进行签名，所以现在我们不需要后端介入，前端完全可以独立完成微信 SDK 的接入。此外，像我们内部和商家端 SSO 登录逻辑的接入也都完全由前端独立完成。

### 技术选型的思考

对于前端的技术选型，我们始终保持理性、拥抱的态度，不会为了盲目求新而引入新的技术。技术选型是针对我们目前大团队的场景，为了解决以往协作过程中发现的一些痛点和不足。比如引入 Node.js 是为了改进前后端的工作流和效率，提升前后端的开发体验。再比如目前我们项目中采用的 AngularJS、React 也是针对特定的业务场景，为了提升开发效率、增强代码的可维护性。在我们的业务应用中，面向商家、后台的一些增删改查系统，AngularJS 能够显著地提升开发效率，而 React 我们目前只是在面向用户的 PC 端项目中做一些尝试和实践。

### 带来的挑战

这样的分工和架构模式在给前端带来更多可能性与便利的同时，也带来了不小的挑战。相比传统的前端角色而言，我们需要更多地关注线上服务的状态，进程内存占用、CPU 占用的详细状况，以及线上异常的监控等。在我们拥抱 Node.js 的同时，对前端的能力要求是更上一阶的。一段看起来正常的 JavaScript 代码，在浏览器端和在 Node 端两种不同的运行环境下，就可能会暴露出一些以往关注不到的问题。比如内存泄露：一个闭包或者一个用于缓存数据的对象，跟浏览器不同，Node 对内存泄露十分敏感，因为线上应用有成千上万甚至百万计的流量，所以哪怕是一个字节的内存泄露也会造成内存堆积，从而导致垃圾回收过程耗时增加，应用响应缓慢，直到进程内存溢出、应用重启或崩溃。

#### 内存泄露问题的定位

以下是我们在生产环境中遭遇的一个案例：最近发现线上服务的内存占用在服务重启后会呈线性的增长，进程启动18小时后，内存就已经占用接近1.6 G 左右，之后不久便会超过 V8 的内存限制导致服务重启。从图2可以看出，在修复之前，内存使用情况一直在随时间进行周期性的波动，波动是因线上 Node 进程不断重启而导致的。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/572865b270d04.jpg" alt="图2  线上服务内存占用情况统计" title="图2  线上服务内存占用情况统计" />

图2  线上服务内存占用情况统计

众所周知，在 V8 的垃圾回收机制下，一般的代码很少出现内存泄露的情况，但是一旦出现内存泄露往往较难排查。不过造成内存泄露的本质原因只有一个，就是应当回收的对象没有正常被回收，变成了老生代中的常驻对象。好在借助一些常见的排查工具可以帮助我们定位内存泄露的具体原因：

- v8-profiler

- node-heapdump

- node-mtrace

- Dtrace

- node-memwatch

这里我们使用 node-heapdump 来在模拟访问的条件下生成堆内存的 snapshot，并通过 Chrome 的开发者调试工具对生成的 snapshot 文件进行分析。对比服务刚启动时以及使用 AB 模拟并发访问一段时间后的 heapdump 信息可以比较容易地定位到内存泄露的问题点：Juicer 默认开启了 Cache，会默认对编译后的模板进行缓存。所以随着访问的增长和并发请求，Cache 对象会持续增长且不被回收，于是关闭 Cache 并重新部署上线后，线上恢复正常。

由于在浏览器的场景中运行时间短，且运行在用户的机器上，即便内存使用过多或者内存泄露，也只会影响到用户的终端。而且运行时间短，随着进程的退出，内存也会随之释放，几乎没有太多内存管理的必要，但在 Node 端同样的代码就可能会暴露出问题。

#### 线上服务的运维和监控

前后端分离除了意味着代码仓库的分离、开发协作的分离之外，还涉及到线上服务的独立发布和单独部署。与之俱来的当然是前端如何更好地对线上服务进行更细粒度的运维和监控，我们的 SA 会更多地关注线上服务的整体指标和可用性，而前端更希望能够细粒度地了解线上Node的进程状态以及异常情况。

PM2 是一款优秀且开源的 Node 进程管理工具。我们在 PM2 的基础上做了一些改造，同时在云端部署了数据收集、数据实时获取的服务，从而形成了我们目前已经应用到线上的 Node 部署监控平台 PM25，它可以将线上 Node 服务进程级别的细粒度信息聚合在云端进行处理和可视化展现，PM2.5 能够监控 Node Server 和进程的各项指标状态，且可以配置报警并在各终端（Web、iPhone、Apple Watch）展示。

### PM2.5 的服务架构

简单介绍下 PM25 的服务架构（如图3所示）：生产环境的 Node 服务通过 PM2.5 CLI 进行部署，PM25 CLI 会持续不断地将 Node 进程的各项数据上报到 PM2.5 的云端。云端收到上报的数据后会对原始数据进行处理并存储至 MongoDB。而 Web 端和 iOS 应用都会通过 WebSocket 服务从服务端获得实时的数据流，然后通过前端进行可视化的信息展示。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/5728660bc408a.jpg" alt="图3  PM2.5服务架构" title="图3  PM2.5服务架构" />

图3  PM2.5 服务架构

#### PM2.5 的内部实现

当 Node 进程通过 PM2.5 启动时，PM2.5 CLI 会同云端服务进行握手，握手成功后才会源源不断地上报数据。上报时首先会将数据进行 AES256 加密，然后使用 TCP 通信将数据上报到服务器，这里用到了开源的 Axon，云端服务器收到数据后会将数据入库存储到 MongoDB 中。同时会进行监控报警的扫描，如果当前数据符合用户订阅的监控报警条件，则会通过云端的 Push 服务向 iOS 客户端推送报警信息。云端同时运行 WebSocket 服务，为多个终端（Web 平台、iOS 应用）提供实时数据的推送。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/572866a6d823a.jpg" alt="图4  PM2.5内部实现" title="图4  PM2.5内部实现" />

图4  PM2.5 内部实现

### 其它监控设施的接入

为了确保线上服务的可靠、稳定，我们还接入了其它一些监控设施和日志平台，便于对线上的错误和访问日志进行追踪、分析和定位处理。

#### Zabbix

Zabbix 是一种分布式系统监控以及网络监控功能的企业级开源中间件，常被运维使用。Zabbix 主要用于对服务进行心跳检测、监控服务的各项指标，当某些指标异常或超过设定的阈值时进行短信、大象、邮件的报警。

#### Sentry

Sentry 是一个错误日志收集处理服务器，可以将程序错误的详细情况集中捕获，而且提供各种常见语言的 SDK 供业务接入。但 Sentry 在服务器端会有采样，一般不能替代实时错误日志报警的监控。

#### 日志监控平台

日志监控平台是美团内部的一个日志收集系统，目前美团统一使用 Flume 收集日志，Flume 具有接收 Scribe 格式日志的能力，而日志监控平台也是以 Scribe 格式日志来收集。日志在整个收集流程中以两种形式存在，分别是原始日志和解析后的日志。目前我们使用日志监控平台主要用于将访问日志的格式化数据上报，之后就可以通过 Hive/Presto 对访问数据进行查询了。

#### 性能监控平台

性能监控平台为美团各平台和产品线提供了简单易用、端到端的性能数据服务。同时也提供了各种常见语言的 SDK 供业务接入，主要用于分析 Node 端的接口响应，以及浏览器端的页面载入性能。

### 小结

以上是美团酒店前端在应用 Node 进行全栈开发的过程中摸索前行的一些心得，也是引子。主要介绍了我们酒店事业部的前后端分离架构，线上内存泄露问题的排查，和所使用的 Node 服务监控平台 PM2.5。目前 PM2.5 的完整实现也已经开源（代码托管于 Github，项目地址为：http://pm25.io/）。 
