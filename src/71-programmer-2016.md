## VR 和 AR 需要什么样的自然表达？



文/毛文涛

### 寻找最自然的人机交互方式
人从有主观意识起，一直在寻找着与客观世界沟通最有效、便捷的方式。在计算机领域，人们也在不断地尝试与计算机对话，希望能被计算机所理解，形成一种自然的人机互动。上世纪人本主义背景下诞生的人体工程学，本质上就想解决这个问题，不再以机器为中心，而是以人为本，围绕人的感官体验、人的操作便捷、工作效能为基本，去要求计算机能听懂、读懂人类。

一开始，我们需要用特殊的语言（编码）、特殊的介质（键盘、鼠标、触摸屏）去告诉计算机该执行的命令，而对于这种方式，人类也一直在突破和改进，想要用最自然、最直接的方式去表达。那么，对于人而言，这种方式是什么？又如何实现？ 

人类经过几百万年的进化，一些日常的动作方式成为了身体本能反应。比如说，我们习惯用身体移动来表达位置信息，用头部旋转来选择视野范围，用说话和面部表情来交流沟通，用动作手势直接进行交互。那对于计算机来说，对人类的理解就需要从这些日常习惯动作开始识别，它们不单单是要理解这些动作表征的区别，更需要理解人类这些动作的表达内容。

### 自然的人机交互离我们越来越近
近年来“人工智能”、“机器学习”、“深度学习”这些词的频繁出现，让我们感受到了人机交互领域的快速发展。计算机变得越来越“聪明”，除了在和人对战围棋中表现出色，计算机已经具备读懂人脸表情的能力（表情识别技术），也能慢慢地听懂我们说的话（语音识别技术），现在，我们可以说计算机已经一定程度上理解人类自然表达的内容了。

计算机已经开始能识别人的自然表达，那么是不是意味着，在 VR 和 AR 应用中，人机交互就能自然地交互呢？可能答案并不会那么地乐观。

### VR 和 AR 需要什么样的自然表达？
很多人都很喜欢玩第一人称射击类游戏，因为沉浸感很强。2013年当 Oculus 出来的时候，大家觉得机器更酷了、沉浸感更强了，因为计算机更能理解人的自然表达方式，比如当我们头部旋转，看不同方向的内容时，我们在头盔中看到的效果和人眼看到的真实效果一致，让人真的感觉置身虚拟场景之中。但这还远远不够，人的需求不仅限于转头看360°全景内容，还希望无限制地移动、无障碍地交互。

要想实现人在虚拟世界中与在真实环境中体验一致，需要自然的表达和智能的理解。不仅对于游戏领域如此，对于教育、医疗、展览展示、模拟训练、建筑工程等其它 VR、AR 可应用的领域也是必须的。

目前市面上的头盔通过 IMU 基本实现了头部旋转。而在位置追踪方面，国外几家知名厂商能够较好地实现，方法各异，主要分为两大类：

1. 借助外接设备，比如 Oculus、PS VR、HTC Vive 等，通过外置设备来捕捉人在空间中的位置移动；

2. 使用内置设备实现，比如 Google Tango 用的是手机里的摄像头，而 uSens 则采取通过 inside-out 方式将摄像头内置在头盔里的方案。

第一种方式需要一定的场地及外设配置，第二种方式则对算法和计算资源要求较高。但从用户体验的角度来看，整合为一体的方式显然更加便捷、简单，随时随地，随想随用。

以上讨论的是基于自然表达中的位置追踪问题，接下来谈谈 VR/AR 中的交互，这是另一种自然表达的需求。我们调研过很多初次体验 VR 的用户，当人们第一次置身于一个陌生的虚拟环境中时，首先想做的是用手去触摸，但很遗憾，大部分 VR 头盔目前并不能很好地支持，这就是手势识别和追踪技术的价值所在。计算机是否能通过各种技术实现对手的定位和识别，决定了 VR 或者 AR 是否能到达下一个层次的体验。

目前进行手势追踪主要采用如下两种实现方式：一是使用传感器设备，用户需要穿戴传感器手套或使用手持外设；二是不借助任何设备，直接用自然手势交互（如图1所示）。前一种方式，需要固定的场所，或者设备的安装和校准，安装和学习成本都很高，主要应用于重度游戏玩家，场景为射击、竞速等大型游戏。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/57284f9f58feb.png" alt="图1  自然手势交互使用场景" title="图1  自然手势交互使用场景" />

图1  自然手势交互使用场景

通过手的自然表达来进行交互，符合人体认知，能创造深度沉浸，它通过计算机视觉算法来识别人自然的手，虽然研发难度较高，但是这种方式对于使用者来说零门槛，也不需要佩戴任何设备，老人、小孩上手就能用，更适合广大普通消费群体。

### VR/AR 需要自然手势带来的超强沉浸感

众所周知，VR/AR 要能呈现好的效果就必须有较强的沉浸感（临场感），而沉浸感较强的 VR/AR 必须具有知觉渠道多、情节统合完整、介入感强等特点。而自然人机交互正是实现超强临场感的必备条件。比如说，如果要在 VR 世界里去拿一个苹果。在拿之前，就有心理和认知预设，我们需要把手掌张开，五个指头一起去抓。但如果不用自然手势，而要用手柄去抓苹果，就会与人类习惯性的行为相悖，与真实世界的动作逻辑不符合，而产生一种“跳戏”的感觉，它会提醒我们——你现在看到的 VR/AR 事物都不是真的！由此极大地降低了沉浸感。

另外，还有一点非常重要，就是力反馈问题。在现实生活中，我们抓苹果后，苹果会给予手一个力的反馈，但是目前在 VR/AR 里还不能完全达到。不过，我们可以通过声音、视觉、触感等反馈方式，尽可能地给人提供更为酣爽的沉浸感。

手势识别尽管用途广泛，但发展了很多年，却一直没有在生活中普及。其实，现在很多家庭里的电视、电脑已经具备手势控制的功能。但是为什么不能普及应用呢？一方面，由于之前技术发展还不够成熟，硬件的计算能力还不够强，所以精度、稳定度都不如鼠标、遥控器，还没达到完全自然交互的要求。

另一方面，对手势交互的场景的定义出现了问题，相比较使用鼠标和遥控器，为了实现同样的功能，人需要抬着胳膊去操作，这并不是用户的一个刚性需求。尤其是简单地将 2D 交互的方式推广到 3D 应用中，这样使得手势交互显得画蛇添足。

然而在 VR 和 AR 应用里，自然手势交互成为一种刚需（如图2所示），如前面所说的 VR/AR 需要沉浸感，鼠标和遥控器不再满足人对交互的需求，并且随着移动设备的计算能力的不断提升，结合先进算法的优化，手势追踪已经能够达到精准和超低延迟，尤其是近两年，软硬件的技术突破，让手势的自然交互变成现实。同时，全新的 3D 交互空间使得我们重新去定义 3D 的交互方式，让手用更加自然的方式去交互。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/5728500f92c8c.png" alt="图2  VR世界里的自然手势操作——移动书籍" title="图2  VR世界里的自然手势操作——移动书籍" />

图2  VR 世界里的自然手势操作——移动书籍

### 2D 平面交互将成过去，物理碰撞机制是 3D 交互新基础

虽然大家对便捷自然的手势交互应用充满期待，但也会有一些疑虑：如果长期进行空中操作，手会不会累？其实，这是一个误区。很多人将 3D 手势交互看成是将传统的键盘变成悬浮在空中的键盘。所以按照我们固有的操作习惯，就得对着空中的键盘噼里啪啦一顿打字，一阵按钮，悬在空中的小臂必然会酸累。

这种直接将平面映射到 3D 空间的方式，并不是大众所需要的 3D 交互方式，我们必须打破 2D 的平面交互思维模式。实际上，我们需要的并不是一个竖起来的键盘，而是一个符合人最自然、最本能的交互设计。

突破以前的鼠标、键盘、触摸屏，将交互设计还原到真实生活中。想一想，当你伸手触碰到一个苹果的时候，你知道苹果离你到底有多少厘米吗？这是不可能的。那我们如何知道碰到了苹果呢？因为“碰”到了。3D 交互的基础是“物理碰撞机制”，通过虚拟事件中的碰撞判断来告诉用户是否完成了动作，而不需要用户用眼睛计算距离，然后判断是否有碰到物体。所以我们并不需要一直使用手去精确控制，比如准确移动到一个空中某个的位置，再进行操作。这些操作可以还给身体和头部。人本来就是通过身体移动来表达位置，用头的方向来选择关注的范围。让手不需要一直抬着，就像我们日常生活一样，大家顾虑的手酸、手累，就将不再成为问题。这就需要交互设计师们突破旧有的设计思维，按照人生活中最自然、最本能的行为习惯去设计内容。手势交互技术已经成熟，也许接下来的重点就是如何设计更自然的交互这个主题。

从手势交互发展来说，也有着从低到高的不同发展水平。第一阶段是对静态手势的识别，这是相对简单的，比如一个造型、手掌、手指，识别对象都是基于静态图片的；第二个阶段是对动态手势的识别，这是基于一小段时间的动作识别，比如滑动和点击，这个阶段是大多数人理解的手势识别；最后一个阶段就是实现自然手势识别，没有特定限制没有时间限制，完全自然手势姿态都能进行识别和跟踪，这和人的理解方式是完全一致的。

<img src="http://ipad-cms.csdn.net/cms/attachment/201605/572851902ea62.jpg" alt="" title="" />