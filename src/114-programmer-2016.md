## 如何构建高质量 MongoDB 云服务

文/杨成虎

>作为一款云数据库产品，SLA 就代表着云服务的质量。SLA 是一个综合性体系结构，好比建房子，高质量的地基，配合高质量的框架，多个层面相结合，这样的房子（系统）才能抗地震、抗台风。本文给大家介绍下阿里云数据库团队的“建筑师”是如何建造 MongoDB 这座金字塔的。

### 部署架构

架构设计上讲究节点冗余，避免单点。阿里云 MongoDB 就采用了三节点的部署方案。

一般情况下，产品对数据库服务可用性的 SLA 要求是3个9，但我们还是先进行了理论计算，假设每台机器每月的故障概率是1%，节点宕机恢复需要7个小时。那么，在单节点情况下，整年无故障可能性是0.886385%，可悲的0个9，两节点的无故障的概率4个9，三节点的无故障概率达到了8个9。所以在理论上，两个节点刚刚符合 SLA 条件。但实际情况下各种现实因素的原因，比如程序 Bug、硬件批次问题、驱动 Bug 等因素，非常容易突破理论数值。需要额外说明一下“每月的故障概率是1%”是基于笔者个人经验，实际的数值读者可以根据现有系统进行统计和计算，笔者并不对“1%”数值的准确性负责。

另外，选择三个节点还有一个重要的原因，两节点非常难处理脑裂问题，在故障发生时，尤其是网络割裂的情况下，不依靠外界系统是无法正确选出可用 Primary 节点。而脑裂一旦发生，很有可能造成两个节点的数据不一致，很多核心业务系统会发生灾难性的后果。而三节点部署的场景下，故障发生时则可以依靠选举算法，利用多数派原则重新构建出 Primary 节点，保证服务高可用、数据高可靠。MongoDB 在这方面相比其他数据库而言，具有一定的先进性，自身支持类似 Raft 的选举算法。

那是不是节点越多就越好呢？更多节点数量当然会带来更高的 SLA 指标，但是过多的节点也是有负面作用的：首先会带来更多的资源消耗，同步关系拓扑结构也更加复杂；其次从工程性的角度上来说，越复杂的系统，可靠性就越差；另外，从产品的角度上看，也要平衡整体系统成本和售卖价格。所以，权衡利弊后的决定是采用三节点方案点作为整个阿里云 MongoDB 云服务的架构基础。对于有自建 MongoDB 需求的用户，推荐三节点的部署方案。

### 故障自恢复

作为云服务的提供商，还需要额外考虑故障恢复的处理。总不能在一个节点失效后，一直放在那里，任其报警，云服务有一个重要特色就是自动化运维。所以，阿里云会对故障节点进行自动处理，尝试重新拉起。这里就出现疑问了，如果节点容器（物理机）故障了，有很大的可能性需要下线处理。也就是拉起失败，但又不能放任不管，所以资源管理系统会重新分配容器，启动新的服务节点，新的服务节点会有新的 IP 地址。这对整个 MongoDB 服务来说，就是访问 URL 地址的变化，传统的处理方式是采用 DNS 域名替代 IP，做过运维系统的人也都知道 DNS 更新在一定程度上非常不可控，客户端可能配置了较长时间的缓存，甚至可能硬编码IP地址到程序中，云服务提供商对公有云用户来说更加不可掌控。阿里云提供了 Application Load Balancer（ALB）服务，利用 VIP 技术，对后端真实的 IP 地址进行了一层映射，也就是说 VIP 地址不变，后端真实 IP 地址根据资源的情况做出相应的变化。在整个服务架构上，每个 MongoDB 云服务实例都会提供两个 VIP 地址，分别对应 Primary 节点、Secondary 节点；另外一个节点并没有提供 VIP 供用户访问，因为第三节点一直作为 Hidden 角色存在，不提供外部访问通道。所有的后台任务、备份、数据导出等都通过此 Hidden 节点完成，把用户和后台系统对数据访问的通道隔离了开来如图1所示。

<img src="http://ipad-cms.csdn.net/cms/attachment/201611/581831867ea0c.png" alt="图1 故障自恢复逻辑图" title="图1 故障自恢复逻辑图" />

图1 故障自恢复逻辑图

### OPLOG 自调整

熟悉 MongoDB 的读者都知道，MongoDB 的数据同步依靠的是其自身的 OPLOG 机制，目标节点会顺序地拉取 OPLOG 内容，然后进行动作重放。OPLOG 是一种特殊的固定总容量大小的数据结构，类似循环队列，内容反复滚动，最新的数据覆盖最旧的数据。疑问又来了：既然是固定大小，那设置多大合适呢？

如果偏小，在需要添加全新节点的场景下，很有可能由于 OPLOG 内容不足，同步失败。由于在线业务数据不断的写入可能冲刷旧的 OPLOG 内容，而同步动作最后一步就是重放同步动作伊始时的全部 OPLOG。这也会间接的影响云服务 SLA，一旦节点失效，整个系统从三节点降级为两节点，而不能再通过添加新的节点去解决。

但如果偏大，就会导致空间浪费，且 OPLOG 是没有索引的，数据越大，第一次访问带来的损耗也越大。

在云上，OPLOG 的设置问题更加头痛，每个客户的使用场景各不相同，但最后要设置多大的 OPLOG 呢？非常难以衡量。所以，我们对 OPLOG 功能进行了加强，从 MongoDB 源码的角度上改进，做到了动态调整 OPLOG，当每个节点同步都完成后，批量地删除掉多余的 OPLOG 数据见图2。

<img src="http://ipad-cms.csdn.net/cms/attachment/201611/58183190522e2.png" alt="图2 OPLOG自调整逻辑图" title="图2 OPLOG自调整逻辑图" />

图2 OPLOG 自调整逻辑图

### 故障感知

在架构上保证高质量就要来看些细节了。上面也说到，MongoDB 具备三节点选举能力，发生故障时可以自我选举。这套逻辑的背后，是基于节点心跳检查，发现心跳丢失后，即认为集群异常，选举动作会在心跳正常的节点中找到合适的 Primary。可现实总是过于残酷，MongoDB 现有心跳设计在很多场景下并不能发挥其作用。

例如 IO Hang 故障，数据无法落盘，甚至不可写，此时节点相当于不可用（虽然进程仍然存活）。MongoDB 原有的心跳行为仅仅是发送心跳包，处理相对简单，对这种情况无法感知。所以阿里云数据库团队引入了一套自检模块，它会定期去扫描节点健康状况，一旦发现系统健康状况下降就会阻止心跳的发送，以此达到一种“自杀”的效果，MongoDB 集群自动将此节点剔除。这套自检算法，要适应短暂或偶尔的健康状况低下，避免误判导致的频繁切换见图3。

<img src="http://ipad-cms.csdn.net/cms/attachment/201611/581831a1ca71b.png" alt="图3 故障感知逻辑图" title="图3 故障感知逻辑图" />

图3 故障感知逻辑图

### 故障预知

到了这一步，再想提高系统质量，就要有些创新思路。也就是，我们能不能不让故障发生，或者说故障发生时是否可以做到无害？现实世界中，地震、海啸等自然灾害，人类是无法抵抗的，但技术的进步，可以让我们预知发生的可能性，那就可以疏散人群。同样，我们也通过大数据能力去预知系统故障，这样就可以做出更平稳的迁移动作，甚至对用户无感知见图4。

<img src="http://ipad-cms.csdn.net/cms/attachment/201611/581831bd13b37.png" alt="图4 MongoDB系统构建好似金字塔" title="图4 MongoDB系统构建好似金字塔" />

图4 MongoDB 系统构建好似金字塔

阿里云数据库团队在做 RDS 服务时就产生了这个想法，所以做了一套“天象”系统，阿里云 MongoDB 也接入了这套体系。

“天象”把每个节点上的数据信息全部收集了起来，包括 CPU、内存、网卡、操作系统，甚至还会采集 TCP 的流量包。有了这些信息，就可以构建出大数据监控体系。通过数据曲线拟合，对比分析，智能地判断出系统状况。举个例子，如果某一台机器的内存访问速度大幅度慢于同类机器的指标，那非常有可能是内存的 ECC 校验出了问题，发现后进行预警，甚至是自动下线。再比如，云服务中最难处理的 CPU 场景，在传统的运维系统中，往往需要经验丰富的工程师根据自身经验来判断各项指标才能搞清楚，借助大数据的能力，可以直接交给天象系统来判断。如图5所示，天象系统准确地判断出 CPU 争抢的时间段，甚至给出触发进程。有了这样的信息，就可以采取一系列的隔离或迁移动作。

<img src="http://ipad-cms.csdn.net/cms/attachment/201611/581831ea85422.jpg" alt="图5 天象系统判断出CPU争抢的时间段" title="图5 天象系统判断出CPU争抢的时间段" />

天象系统判断出 CPU 争抢的时间段

### 资源到服务

阿里云 MongoDB 云服务，之所以能成为服务，并不仅仅是做资源的托管，资源的高质量稳定托管只是云服务的基石。服务能力上我们提供了强大的备份恢复功能，可恢复到任意时间点的能力。还有审计日志收集，高效地抓取业务请求行为，供用户来审计操作行为，还有深层次的内核性能优化。重要的是借助阿里云数据库产品的丰富多样性，提供强大的异构数据库系统解决方案。

### 总结和未来的发展

整套系统的构建，也好似金字塔一样。底座就是保证架构的防故障能力，没有架构的保证，再多的功能和特性，都只能是花瓶。在此基础之上，逐渐叠加“自恢复”、“自检”，最后利用好强大的大数据处理能力赋予整个云服务“预知”能力。